{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb47705c",
   "metadata": {},
   "source": [
    "## 0. 필요한 라이브러리 import 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04fdbb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea113adc",
   "metadata": {},
   "source": [
    "## 1. Train 데이터 불러오기 및 Resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6402c38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b73929",
   "metadata": {},
   "source": [
    "#### 이미지 크기 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e9c6b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "img00 = Image.open(image_path + \"/0.jpg\")\n",
    "img00.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b44a468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 바위 images resized.\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "images=glob.glob(image_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    "\n",
    "print(len(images), \"바위 images resized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6cf3d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 보 images resized.\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "images=glob.glob(image_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    "\n",
    "print(len(images), \"보 images resized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc68d19",
   "metadata": {},
   "source": [
    "## 2. 가위: 0, 바위: 1, 보: 2 로 라벨링 하고 정규화 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e76273",
   "metadata": {},
   "source": [
    "### Train data resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "106adac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,\n",
    "                  dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c2e1c9",
   "metadata": {},
   "source": [
    "### 이미지 프린팅 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4762cbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4ecaa7",
   "metadata": {},
   "source": [
    "### Test data resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a185869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images resized.\n",
      "100  images resized.\n",
      "100  images resized.\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "images=glob.glob(image_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    "\n",
    "print(len(images), \" images resized.\")\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "images=glob.glob(image_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    "\n",
    "print(len(images), \" images resized.\")\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "images=glob.glob(image_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    "\n",
    "print(len(images), \" images resized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7a9d60",
   "metadata": {},
   "source": [
    "## 3. 딥러닝 네트워크 설계하기\n",
    "Train data labeling 및 네트워크 모델링 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8d1684c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 225,610\n",
      "Trainable params: 225,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,\n",
    "                  dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    if img_path[-5:] == 'paper':\n",
    "        print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    else:\n",
    "        print(\"테스트데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "train_data_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(train_data_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "\n",
    "# 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 3)\n",
    "\n",
    "# 바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_dense=128\n",
    "n_train_epoch=40\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba2ab1c",
   "metadata": {},
   "source": [
    "## 4. 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc39ed35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "10/10 [==============================] - 3s 12ms/step - loss: 1.7082 - accuracy: 0.2967\n",
      "Epoch 2/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.2301 - accuracy: 0.3100\n",
      "Epoch 3/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1735 - accuracy: 0.2867\n",
      "Epoch 4/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1266 - accuracy: 0.2900\n",
      "Epoch 5/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1326 - accuracy: 0.3400\n",
      "Epoch 6/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1079 - accuracy: 0.3233\n",
      "Epoch 7/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1035 - accuracy: 0.3433\n",
      "Epoch 8/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1225 - accuracy: 0.3067\n",
      "Epoch 9/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1168 - accuracy: 0.3033\n",
      "Epoch 10/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3867\n",
      "Epoch 11/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0949 - accuracy: 0.4033\n",
      "Epoch 12/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0885 - accuracy: 0.3567\n",
      "Epoch 13/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0706 - accuracy: 0.5200\n",
      "Epoch 14/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0697 - accuracy: 0.5133\n",
      "Epoch 15/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0538 - accuracy: 0.4000\n",
      "Epoch 16/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0979 - accuracy: 0.4067\n",
      "Epoch 17/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0720 - accuracy: 0.4067\n",
      "Epoch 18/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0281 - accuracy: 0.6267\n",
      "Epoch 19/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0009 - accuracy: 0.5100\n",
      "Epoch 20/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9723 - accuracy: 0.5267\n",
      "Epoch 21/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9378 - accuracy: 0.6133\n",
      "Epoch 22/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9270 - accuracy: 0.5600\n",
      "Epoch 23/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8686 - accuracy: 0.6767\n",
      "Epoch 24/40\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7948 - accuracy: 0.7667\n",
      "Epoch 25/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.8000\n",
      "Epoch 26/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6680 - accuracy: 0.8200\n",
      "Epoch 27/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.8133\n",
      "Epoch 28/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.8233\n",
      "Epoch 29/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.8800\n",
      "Epoch 30/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.8100\n",
      "Epoch 31/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.8200\n",
      "Epoch 32/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.9100\n",
      "Epoch 33/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.9133\n",
      "Epoch 34/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8500\n",
      "Epoch 35/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3139 - accuracy: 0.9400\n",
      "Epoch 36/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.9367\n",
      "Epoch 37/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3062 - accuracy: 0.8967\n",
      "Epoch 38/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2613 - accuracy: 0.9433\n",
      "Epoch 39/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2435 - accuracy: 0.9267\n",
      "Epoch 40/40\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4fd010eb50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eb7486",
   "metadata": {},
   "source": [
    "## 5. 얼마나 잘 만들었는지 확인하기(테스트)\n",
    "Test data 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a70c519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "test_data_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(test_data_path)\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "# 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8815e71",
   "metadata": {},
   "source": [
    "#### Loss 및 Accuracy 측정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65c27c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 4.4620 - accuracy: 0.4033\n",
      "test_loss: 4.46201229095459 \n",
      "test_accuracy: 0.4033333361148834\n"
     ]
    }
   ],
   "source": [
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f113d7",
   "metadata": {},
   "source": [
    "#### Loss 값이 크고 Accuracy 값이 너무 작다.\n",
    "라이퍼 파라미터값을 변경시켜봐도 좀처럼 나아지지 않는다.\n",
    "\n",
    "데이터 양이 너무 적은것이 하나의 원인일것으로 생각된다.\n",
    "\n",
    "개선할 다른 방법은 어떤것이 있을까."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
