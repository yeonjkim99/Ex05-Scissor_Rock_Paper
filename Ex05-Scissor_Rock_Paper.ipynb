{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59fa52a4",
   "metadata": {},
   "source": [
    "## 0. 필요한 라이브러리 import 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb29b971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd527525",
   "metadata": {},
   "source": [
    "## 1. Train 데이터 불러오기 및 Resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3f840a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500  images to be resized.\n",
      "500  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "img_size = 28\n",
    "color = 3\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 img_size x img_size 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(img_size,img_size)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f81fc4a",
   "metadata": {},
   "source": [
    "#### 이미지 크기 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08f3304b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "# image_path = os.getenv(\"HOME\") + \"/aiffel/03.Exploration/Ex05/scissor\"\n",
    "img00 = Image.open(image_path + \"/0.jpg\")\n",
    "img00.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8ed10b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 바위 images resized.\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "images=glob.glob(image_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 img_size x img_size 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(img_size,img_size)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    "\n",
    "print(len(images), \"바위 images resized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52bb0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 보 images resized.\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "images=glob.glob(image_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 img_size x img_size 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(img_size,img_size)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    "\n",
    "print(len(images), \"보 images resized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e159679f",
   "metadata": {},
   "source": [
    "## 2. 가위: 0, 바위: 1, 보: 2 로 라벨링 하고 정규화 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2caf2f",
   "metadata": {},
   "source": [
    "### Train data 라벨링 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aad84d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 1500 입니다.\n",
      "x_train shape: (1500, 28, 28, 3)\n",
      "y_train shape: (1500,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=1500):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,\n",
    "                  dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e59dd63",
   "metadata": {},
   "source": [
    "### 이미지 프린팅 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "760c601e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ce3e99",
   "metadata": {},
   "source": [
    "### Test data resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2715410c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images resized.\n",
      "100  images resized.\n",
      "100  images resized.\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "images=glob.glob(image_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 img_size x img_size 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(img_size,img_size)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    "\n",
    "print(len(images), \" images resized.\")\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "images=glob.glob(image_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 img_size x img_size 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(img_size,img_size)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    "\n",
    "print(len(images), \" images resized.\")\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "images=glob.glob(image_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 img_size x img_size사이즈로 바꾸어 저장합니다.\n",
    "target_size=(img_size,img_size)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    "\n",
    "print(len(images), \" images resized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac783f0",
   "metadata": {},
   "source": [
    "## 3. 딥러닝 네트워크 설계하기\n",
    "Train data labeling 및 네트워크 모델링 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b697a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 1500 입니다.\n",
      "x_train shape: (1500, 28, 28, 3)\n",
      "y_train shape: (1500,)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 65,930\n",
      "Trainable params: 65,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def load_data(img_path, number_of_data=1500):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,\n",
    "                  dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    if img_path[-5:] == 'paper':\n",
    "        print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    else:\n",
    "        print(\"테스트데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "train_data_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(train_data_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "\n",
    "# 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "x_train_reshaped=x_train_norm.reshape( -1, img_size, img_size, color)\n",
    "\n",
    "# 바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_channel_3 = 64\n",
    "n_dense=128\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(img_size,img_size,color)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0372efc3",
   "metadata": {},
   "source": [
    "## 4. 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a450774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "47/47 [==============================] - 1s 6ms/step - loss: 1.2980 - accuracy: 0.3327\n",
      "Epoch 2/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 1.1078 - accuracy: 0.3533\n",
      "Epoch 3/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 1.0597 - accuracy: 0.4433\n",
      "Epoch 4/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9876 - accuracy: 0.5160\n",
      "Epoch 5/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.8318 - accuracy: 0.6173\n",
      "Epoch 6/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.7533\n",
      "Epoch 7/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7980\n",
      "Epoch 8/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8367\n",
      "Epoch 9/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8713\n",
      "Epoch 10/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.8987\n",
      "Epoch 11/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2371 - accuracy: 0.9153\n",
      "Epoch 12/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2262 - accuracy: 0.9160\n",
      "Epoch 13/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1811 - accuracy: 0.9353\n",
      "Epoch 14/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1529 - accuracy: 0.9487\n",
      "Epoch 15/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9320\n",
      "Epoch 16/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1404 - accuracy: 0.9453\n",
      "Epoch 17/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1901 - accuracy: 0.9280\n",
      "Epoch 18/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1204 - accuracy: 0.9540\n",
      "Epoch 19/20\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0925 - accuracy: 0.9687\n",
      "Epoch 20/20\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0735 - accuracy: 0.9807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f73b0609940>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba8ed98",
   "metadata": {},
   "source": [
    "## 5. 얼마나 잘 만들었는지 확인하기(테스트)\n",
    "Test data 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec367383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (1500, 28, 28, 3)\n",
      "y_test shape: (1500,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "test_data_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(test_data_path)\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "# 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "x_test_reshaped=x_test_norm.reshape( -1, img_size, img_size, color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc765f17",
   "metadata": {},
   "source": [
    "#### Loss 및 Accuracy 측정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffb0c9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 - 0s - loss: 1.3147 - accuracy: 0.8820\n",
      "test_loss: 1.314746379852295 \n",
      "test_accuracy: 0.8820000290870667\n"
     ]
    }
   ],
   "source": [
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c9fdd2",
   "metadata": {},
   "source": [
    "#### Loss 값이 크고 Accuracy 값이 너무 작다.\n",
    "라이퍼 파라미터값을 변경시켜봐도 좀처럼 나아지지 않는다.(Loss: 4.46, Accuracy: 0.40)\n",
    "\n",
    "Channel수를 3개로 늘려보니 조금 나아졌다.(Loss: 3.08, Accuracy: 0.47)\n",
    "\n",
    "데이터 양이 너무 적은것이 하나의 원인일것으로 생각되어 기존 100개씩에서 400개씩을 더해 총 500개로 해 보았다.\n",
    "\n",
    "결과가 많이 향상되었다. (Loss: 1.31, Accuracy: 0.88)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
