{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf4b387",
   "metadata": {},
   "source": [
    "## 0. 필요한 라이브러리 import 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e37c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cceca7",
   "metadata": {},
   "source": [
    "## 1. Train 데이터 불러오기 및 Resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd37d092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500  images to be resized.\n",
      "500  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "img_size = 28\n",
    "color = 3\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 img_size x img_size 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(img_size,img_size)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a028816",
   "metadata": {},
   "source": [
    "#### 이미지 크기 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e95fc831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "# image_path = os.getenv(\"HOME\") + \"/aiffel/03.Exploration/Ex05/scissor\"\n",
    "img00 = Image.open(image_path + \"/0.jpg\")\n",
    "img00.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36617dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 바위 images resized.\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "images=glob.glob(image_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 img_size x img_size 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(img_size,img_size)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    "\n",
    "print(len(images), \"바위 images resized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5a43a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 보 images resized.\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "images=glob.glob(image_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 img_size x img_size 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(img_size,img_size)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    "\n",
    "print(len(images), \"보 images resized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0da2988",
   "metadata": {},
   "source": [
    "## 2. Train data 가위: 0, 바위: 1, 보: 2 로 라벨링 하고 정규화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47d8195d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 1500 입니다.\n",
      "x_train shape: (1500, 28, 28, 3)\n",
      "y_train shape: (1500,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, number_of_data=1500):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,\n",
    "                  dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "# 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "x_train_reshaped=x_train_norm.reshape( -1, img_size, img_size, color)\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4fb570",
   "metadata": {},
   "source": [
    "### 이미지 프린팅 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b34eca09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cde3a7",
   "metadata": {},
   "source": [
    "## 3. Test 데이터 불러오기 및 Resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c7ccba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images resized.\n",
      "100  images resized.\n",
      "100  images resized.\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "images=glob.glob(image_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 img_size x img_size 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(img_size,img_size)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    "\n",
    "print(len(images), \" images resized.\")\n",
    "\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "images=glob.glob(image_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 img_size x img_size 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(img_size,img_size)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    "\n",
    "print(len(images), \" images resized.\")\n",
    "\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "images=glob.glob(image_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 img_size x img_size사이즈로 바꾸어 저장합니다.\n",
    "target_size=(img_size,img_size)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    "\n",
    "print(len(images), \" images resized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ff1726",
   "metadata": {},
   "source": [
    "## 4. Test data 가위: 0, 바위: 1, 보: 2 로 라벨링 하고 정규화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b9b8474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (1500, 28, 28, 3)\n",
      "y_test shape: (1500,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, number_of_data=1500):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,\n",
    "                  dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "test_data_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(test_data_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "\n",
    "# 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "x_test_reshaped = x_test_norm.reshape( -1, img_size, img_size, color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc454a",
   "metadata": {},
   "source": [
    "## 5. 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01a70898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 65,930\n",
      "Trainable params: 65,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_channel_3 = 64\n",
    "n_dense=128\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(img_size,img_size,color)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a9ddec",
   "metadata": {},
   "source": [
    "## 6. 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faf25103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "47/47 [==============================] - 3s 6ms/step - loss: 1.3266 - accuracy: 0.3447\n",
      "Epoch 2/20\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0751 - accuracy: 0.3947\n",
      "Epoch 3/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 1.0051 - accuracy: 0.4827\n",
      "Epoch 4/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.8388 - accuracy: 0.6307\n",
      "Epoch 5/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.6947\n",
      "Epoch 6/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7733\n",
      "Epoch 7/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.8120\n",
      "Epoch 8/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3340 - accuracy: 0.8660\n",
      "Epoch 9/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2655 - accuracy: 0.9020\n",
      "Epoch 10/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2350 - accuracy: 0.9120\n",
      "Epoch 11/20\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.1904 - accuracy: 0.9327\n",
      "Epoch 12/20\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.1653 - accuracy: 0.9440\n",
      "Epoch 13/20\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9587\n",
      "Epoch 14/20\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.1157 - accuracy: 0.9647\n",
      "Epoch 15/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0949 - accuracy: 0.9760\n",
      "Epoch 16/20\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0969 - accuracy: 0.9660\n",
      "Epoch 17/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9807\n",
      "Epoch 18/20\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.9833\n",
      "Epoch 19/20\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9893\n",
      "Epoch 20/20\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ef80d3490>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c47ccf",
   "metadata": {},
   "source": [
    "## 7. 얼마나 잘 만들었는지 확인하기(테스트)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d10e30a",
   "metadata": {},
   "source": [
    "#### Loss 및 Accuracy 측정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecac0fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 - 0s - loss: 0.9824 - accuracy: 0.9080\n",
      "test_loss: 0.982365071773529 \n",
      "test_accuracy: 0.9079999923706055\n"
     ]
    }
   ],
   "source": [
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26485541",
   "metadata": {},
   "source": [
    "## 8. 회고\n",
    "1. Loss 값이 크고 Accuracy 값이 너무 작다. 하이퍼 파라미터값을 변경시켜봐도 좀처럼 나아지지 않는다. (Loss: 4.46, Accuracy: 0.40)\n",
    "   \n",
    "\n",
    "2. Channel수를 3개로 늘려보니 조금 나아졌다. (Loss: 3.08, Accuracy: 0.47)\n",
    "\n",
    "\n",
    "3. 데이터 양이 너무 적은것이 하나의 원인일것으로 생각되어 기존 100개씩에서 400개씩을 더해 총 500개로 해 보았다. 결과가 많이 향상되었다. (Loss: 0.98, Accuracy: 0.90)\n",
    "\n",
    "인공지능은 역시 데이터가 많아야 함을 몸소 체험하게 되었다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
